## 主从复制

#### 集成步骤

```properties
slaveof {ip} {port} 从配置文件中添加主节点的ip和端口即可
slaveof no one 在从节点执行该命令即可断开主从模式
```

#### 主从复制原理

* 从节点内部维护主节点的ip和端口
* 从节点通过`replicationCron`函数每一秒执行一次,如果发现主节点,便会根据ip和port通过socket连接,如果链接成功,则为该soket创建一个专门处理复制的文件事件处理器,专门负责后续的复制,接收RDB文件或命令等工作
* 主节点接收到从节点的socket链接后,为该socket创建相应的客户端状态,并将从节点看做链接到主节点的一个客户端(**在主从链接和验证成功,主从会成为对方的客户端,因为主节点会主动推送命令给从节点**),后面的步骤以从节点向主节点发送命令请求的方式进行
* 从节点成为主节点的客户端后,发送`ping`命令进行首次请求 目的:检测socket链接是否可用,以及主节点当前是否能够处理请求,从节点收到的响应情况如下:
  * 返回`PONG` 说明socket链接正常,且主节点当前可以处理请求,复制过程继续
  * 超时 一定时间后从节点仍未收到主节点的回复,说明socket不可用,则断开链接重试
  * 返回PONG以外的结果: 如果主节点返回其他结果,说明主节点当前无法处理该命令,从节点断开重试
* 如果从节点设置了`masterauth` 选项,则从节点需要向主节点进行身份验证,从节点通过向主节点发送`auth`命令,附带配置文件中`masterauth`配置的参数,如果主节点设置了密码,与从节点发送过来的`masterauth`一致,则通过,否则从节点断开链接重试
* 从节点会将自身的端口号发送给主节点,主节点会保存信息到该从节点对应的客户端的`slave_listening_port`字段,仅仅用于`info Replication`命令展示用
* 在数据同步时,除了发送写命令,主从节点还维护这心跳机制 `PING` `REPLCONF ACK <offset>` (`offset`为从节点的偏移量),同时注意命令传播都是异步的过程,即主节点发送命令后不会等待从节点的回复
* `repl-disable-tcp-nodelay no` 表示在命令传播阶段,控制主节点是否禁止与从节点的`TCP_NODELAY` 默认为no,设置yes, tcp则会对包进行合并从而减少带宽,但发送命令的频率会降低,从节点数据延迟增加,一致性会变差, linux内核配置默认40ms, 设置为no,则tcp会立马将数据发送给从节点,带宽增加延迟变小,一般都为no

#### 全量复制(通过`psync`命令进行)

* 从节点无法判断进行部分复制,或者主节点无法判断部分复制时都会进行全量复制
* 主节点收到全量复制命令后,执行`bgsave` 在后台生成RDB文件,并使用一个**复制缓冲区** 用来记录当前时间开始后的写命令
* 主节点`bgsave`执行完成后,会将RDB文件发送给从节点,从节点首先清理自己的旧数据,然后载入新的RDB文件,将数据库状态更新为主节点执行`bgsave`时的状态(该过程是阻塞的)
* 主节点将**复制缓冲区**的所有写命令发送给从节点,从节点执行这些命令后,会保持与主节点一致的状态
* 如果从节点开启AOF,则会触发`bgrewriteaof`,从而保证AOF文件更新至主节点最新的状态

#### 部分复制(通过`psync`命令进行)

* 复制偏移量
  * 主节点和从节点各自维护一个复制偏移量`offset` 代表主节点向从节点发送的字节数,主节点每次向从节点发送N个字节数据,则`offset`会+N,同理,从节点从主节点接收N个字节时,会将自己的`offset`+N
  * `offset` 用来判断主从节点的数据库状态是否一致,如果二者一样,则数据一致
* 复制积压缓冲区
  * 复制缓冲区是主节点维护的,固定长度的,先进先出的队列,默认大小`1MB`,当主节点开始有从节点时创建,无论多个从节点,只有一个复制缓冲区
  * 复制缓冲区除了存储写命令外,还存储了其中的每个字节对应的复制偏移量`offset`
  * 如果主从节点的`offset`的差距超过缓冲区的长度则会进行全量复制,可以通过`repl-backlog-size`来指定缓冲区大小
* 服务器运行的ID(runid)
  * 每个redis在启动时都会自动创建一个随机的ID(每次启动都不一样),该值redis节点的唯一识别码 `info Server`命令可以查看
  * 主从复制时,主节点会将自己的`runid`发送给从节点,从节点将这个`runid`保存下来,当短线重连时,从节点会将这个节点发送给主节点,主节点用来判断是否进行部分复制,`runid`一样则证明之前已经同步过,会尝试进行部分复制,否则说明之前从节点连接的不是**当前的主节点**,会进行全量复制

#### psync命令执行过程

* 如果从节点之前未执行过`slaveof`,或者最近执行过`slaveof no one`,则从节点会发送`psync ? -1` 向主节点请求全量复制
* 如果从节点之前执行过`slaveof`,则会发送`psync <runid> offset ` ,其中`runid`为上次复制时主节点的`runid`,`offset`是从节点上次复制保存的偏移量
* 主节点解析命令来选择是部分复制还是全量复制,如果`runid`与从节点发送的不同或者从节点发送的`offset`不在缓冲区中,则回复`+FULLRESYNC <runid> <offset>` 表示要进行全量复制
* 如果是部分复制,则会回复`+CONTINUE` 从节点只需要等待接收缺少的数据即可

## 哨兵模式

#### 集成步骤

* 先配置主从模式

* 配置哨兵节点

```properties
sentinel monitor {masterName} {masterIp} {masterPort} {quorum} 配置哨兵节点的监控信息
`masterName` 主节点名称
`masterIp` 主节点ip
`masterPort` 主节点端口
`quorum` 判断主节点客观下线的哨兵数的阀值(建议哨兵数/2+1)
```

* 启动哨兵节点

```shell
./redis-sentinel redis.conf
./redis-server redis.conf --sentinel 两则都可以 redis.conf中配置的是哨兵节点信息
```

#### 哨兵节点定时任务(3个)

* 通过向主节点发送`info`命令获取最新的主从结构
* 通经发布订阅功能获取其他哨兵节点的信息
* 通过向其他节点发送`ping`命令进行心跳检测,判断是否下线

#### 主观下线

> 在心跳检测的定时任务中,如果其他节点超过一定时间没有回复,哨兵节点会将其进行主观下线

#### 客观下线(主节点)

> 哨兵节点对**主节点**进行主观下线后,通过`sentinel is-master-down-by addr`命令询问其他哨兵节点对该节点的状态;如果哨兵数量达到一定数值,则会对该主节点进行客观下线;从节点或哨兵节点发生故障后则不会有后续的客观下线和故障转移操作

#### 选举领导者哨兵就节点

> 主节点客观下线后,各哨兵节点会进行协商,选举一个<u>领导者</u>的哨兵节点,并由该领导者进行故障转移操作(Raft算法,先到先得)

#### 故障转移

* 从节点中过滤不健康的节点,选择优先级最高的从节点(` slave-priority`指定),如果无法区分,则选择复制偏移量最大的从 节点,如果仍无法区分,则选择runid最小的从节点
* 通过`slaveof no one`(取消从节点)命令,让选出来的从节点变为主节点,并通过`slaveof`将其他节点变为其从节点
* 将已下线的主节点设置为新的主节点的从节点,当其重新上线后,会成为新的主节点的从节点

#### 配置说明

`sentinel down-after-milliseconds {masterName} {time}` 主观判断超时时间

* `time` 哨兵节点通过`ping`检测与其他节点的心跳,如果超过`time`时间没有响应,则会主管认为超时

`sentinel parallel-syncs {masterName} {number}` 故障转移后的从节点复制

* `number` 在主节点切换完成后,其他从节点要发起复制时,如果该值为1,则表示同一时间内只能有一个从节点复制

`sentinel failover-timeout {masterName} {time}` 故障转移超时判断

* 从节点晋升主节点超过`time`或者从节点向新的主节点发起复制操作的时间超过`time`,都会导致故障转移超时失败

#### 配置总结

* `min-slaves-to-write 3` 从节点少于3个时,主节点拒绝执行写命令
* `min-slaves-max-lag 10` 所有节点都都大于10s的延迟时,拒绝执行写操作 延迟数可以通过`REPLCONF ACK`的时间来判断
* `repl-timeout` 主从节点超时时间 默认60s  
* `repl-backlog-ttl` 主节点没有从节点时,复制积压缓冲区保留的时间 默认3600s,如果为0,则永不释放复制积压缓冲区

## 集群模式

#### 集成步骤

* `cluster-enabled yes` `cluster-config-file` 配置文件开启集群模式,指定默认配置文件路径
* `cluster meet {ip} {port}` 各个节点进行握手
* `cluster addslots {0..123}`给主节点分配槽 该命令必须在命令行上完成`redis-cli -p {port} cluster addslots`
* `cluster replicate {runid}` 指定主从关系 ,`runid` 可以根据 `cluster nodes`查询

#### 节点间通讯 (单对单,广播,Gossip协议)

* 在指定端口之外,集群的每个节点都额外暴露一个集群端口=(自定义端口+10000),用于节点之间的通讯,例如搭建集群,增减节点,故障转移等

* `广播` 向集群中的所有节点发送消息,优点:收敛速度快(集群中所有节点获取的集群信息是一致的),缺点:每条消息都要发送给所有节点,CPU,带宽等消耗大
* `Gossip协议` 优点:负载低,去中心化,容错性高,缺点:集群收敛速度慢 
  * 随机找5个节点,选中其中一个最久没有通讯的节点
  * 扫描节点列表,选择最后一次`PONG`消息时间<当前时间-`cluste_node_time/2`的所有节点

#### 集群设计方案

* 高可用要求: 至少3个主节点且不再同一台机器上,至少3个从节点
* 数据量和访问量: 估算应用需要的数据量和访问量(考虑业务冗余),结合每个节点的容量和最大访问量,计算出主节点的数量
* 节点数量限制: 最大1000,主要考虑节点之间的通讯消耗

#### 数据分区方案

> 采用带有虚拟节点的一致性哈希进行分区,一共分为16384个Hash槽, key的算法:CRC16

#### 消息类型

* `METT消息` ,在节点握手阶段通过`cluster meet`命令向新加入的节点发送消息,新节点收到消息后会回复一个`PONG`消息
* `PING消息` 集群中的每个节点都会选择部分节点发送PING消息,接收者返回一个PONG消息,PING消息的内容包含自身节点和其他部分节点的信息用于彼此交换信息以及检测是否在线,默认采用`Gossip协议`
* `PONG消息` PONG消息封装了自身状态数据,一类在接收`MEET/PING`消息后回复的PONT消息,二类节点向集群广播PONG消息,这样其他节点会获得该节点的最新信息
* `FAIL`当一个主节点判断另一个主节点进入FAIL状态时,会向集群中广播这一FAIL消息
* `PUBLISH消息` 节点收到PUBLISH命令后,会先执行该命令,然后向集群中广播这一消息,接收节点也会执行该PUBLISH命令

#### 集群限制问题

* key批量操作受限: `mget` `mset` 批量操作字符串,只有当key都位于一个槽时才能进行,思路1:在客户端维护槽和key的信息,每次针对特定的槽执行`mget``mset`,思路2:采用Hash Tag `{project}:ID` 只对`{}`中的字符串进行hash,这样就能保证同一类在一个槽中
* `keys/flushall` 可以在任意节点执行,但效果只针对当前链接的节点
* 集群模式下只支持db0数据库
* 事务/Lua脚本 集群支持事务和Lua脚本,前提所有涉及到的key必须在同一个节点才行

## RDB持久化

#### RDB持久化

* 手动触发
  * `save` 阻塞Redis服务器进程,直到RDB文件创建完毕 (基本废弃)
  * `bgsave` 创建子进程(如果已经存在子进程在执行bgsave则直接返回),由子进程负责创建RDB文件,主进程则继续处理请求
* 自动触发
  * `save m n` 当m秒中发生n次变化,则会触发`bgsave`

#### 自动触发持久化原理

* `serverCron函数` redis服务器周期函数,每隔100ms执行一次,用来检测`save m n`是否满足条件,满足则执行`bgsave`
* `dirty计数器` 用来记录从上次`bgsave/save` 命令之后,服务器修改了多少次(增删改),而当成功执行完`bgsave/save`后,该值会归零(注意是服务器进行修改,而不是客户端执行了多少命令)
  * `mset k1 v1 k2 v2 k3 v3` dirty值会+3
* `lastsave时间戳` 上次成功执行`bgsave/save`的时间
* 因此自动触发持久化条件必须满足一下两个条件
  * `当前时间`-`lastsave` >`m`
  * `dirty` >= n

#### 配置总结

`stop-writes-on-bgsave-error yes` 当`bgsave`出现错误时,Redis是否停止执行写命令

`rdbcompression yes` 是否开启RDB文件压缩

`rdbchecksum yes` 是否开启对RDB文件校验,(读写都校验)

`dbfilename dump.rdb` RDB文件名

`dir` RDB文件或AOF文件所在的目录

## AOP持久化

#### 执行流程

* `append` 追加命令 将Redis的写命令追加到缓存区`aof_buf`;

  * 写入格式为纯文本,兼容性好,可读性强,操作简单避免二次开销,除了`select x`命令外,其他均由客户端发送过来的写命令

* `write/sync` 文件写入和文件同步,根据不同的策略将`aof_buf`中的数据写入到磁盘,AOF同步文件策略由参数`appendfsync`决定:

  * `always` 命令写入`aof_buf`后立即调用系统`fsync`操作同步到aof文件中,`fsync`完成后线程返回
  * `no` 命令写入`aof_buf`后调用系统write操作,不对aof文件做`fsync`同步,同步由操作系统负责,通常操作系统周期是30s,这种情况下,文件同步不可控

  * `everysec` 命令写入`aof_buf`后调用系统write操作,write完成后线程返回;`fsync`同步文件操作由专门的线程执行,每秒一次

* `rewrite` 文件重写; 定期重写AOF文件,达到压缩目的

  * 将Redis中的数据转换为写命令,写入到新的AOF文件中,不对老AOF文件做任何操作

#### 重写触发

* `bgrewriteaof` 手动触发重写 类似于`bgsave`

* 自动触发 同时满足一下两种情况
  * `auto-aof-rewrite-min-size` 执行AOF重写时,文件的最小体积 默认64M
  * `auto-aof-rewrite-percentage` 执行AOF重写时,当前AOF的体积与上次执行AOF重写后的体积比值 默认100

> 在创建子进程进行AOF重写时,父进程会将新的写入命令分别保存在`aof_buf` (依旧写入到旧AOF文件中)和 `aof_rewrite_buf`缓冲区中,
>
> 待子进程写完新的AOF文件后,向父进程发送信号,父进程将`aof_rewrite_buf`中数据同步给新的AOF文件



## 缓存穿透,缓存击穿,缓存雪崩

#### 缓存穿透

> 指查询一个一定不存在的数据,如果在存储层查询不到则不写入缓存中,这会导致这个不存在的值每次被访问时,都需要到数据库中查询导致DB挂掉

#### 解决方案

* 查询为空时,依旧将结果缓存(可以通过占位符),设置一个较短的过期时间
* 布隆过滤器: 将所有可能存在的数据hash到足够大的`bitmap`中,一定不存在的数据一定会被`bitmap`拦截掉,从而避免对DB的查询

#### 缓存击穿

> 对于设置了过期时间的缓存,在某个时间过期时,恰好有大量并发对这个缓存进行请求,会导致所有请求都直接访问数据库

#### 解决方案

* 互斥锁,在缓存失效时,通过互斥锁只允许一个线程进行访问数据库并加载数据到缓冲中
* 设置永不过期(物理不过期),后台异步线程进行定期刷新操作

#### 缓存雪崩

> 设置缓存时,采用了相同的过期时间,导致某一刻缓存同时失效,请求全部访问DB

#### 解决方案

* 将缓存的过期时间进行分散

## RESP协议

> 结束符为回车换行符 `\r\n`

* 单行字符串 第一个字符为`+`
* 错误信息 第一个字符为`-`
* 整数数字 第一个字符为`:` ,后面跟整数字符串
* 多行字符串,第一个字符为`$` 后面跟字符串长度
* 数组,第一个字符为`*` ,后面跟数组长度